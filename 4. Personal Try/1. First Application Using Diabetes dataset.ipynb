{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../src/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 8 columns):\n",
      "Number of times pregnant        768 non-null int64\n",
      "Plasma glucose concentration    768 non-null int64\n",
      "Diastolic blood pressure        768 non-null int64\n",
      "Triceps skin fold thickness     768 non-null int64\n",
      "2-Hour serum insulin            768 non-null int64\n",
      "Body mass index                 768 non-null float64\n",
      "Age                             768 non-null int64\n",
      "Class                           768 non-null object\n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 48.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split them into values\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y=='positive') + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "x_train = sc.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, no_of_input_features, no_of_output_features):\n",
    "        # We want to take all of the features of the Module class\n",
    "        super(Network, self).__init__()\n",
    "        # our attributes = Layers\n",
    "        # our functionalities = Forward Propagation\n",
    "        self.fc1 = nn.Linear(no_of_input_features, 50) # FC (Fully Connected Layer)\n",
    "        self.fc2 = nn.Linear(50,50)\n",
    "        self.fc3 = nn.Linear(50,no_of_output_features)\n",
    "        # Define activation Function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(x_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/600] and the accuracy is 0.726 and the loss is 0.5400332808494568\n",
      "Epoch [80/600] and the accuracy is 0.767 and the loss is 0.49708324670791626\n",
      "Epoch [120/600] and the accuracy is 0.756 and the loss is 0.4891965389251709\n",
      "Epoch [160/600] and the accuracy is 0.757 and the loss is 0.48699572682380676\n",
      "Epoch [200/600] and the accuracy is 0.757 and the loss is 0.4854632019996643\n",
      "Epoch [240/600] and the accuracy is 0.761 and the loss is 0.48401808738708496\n",
      "Epoch [280/600] and the accuracy is 0.761 and the loss is 0.4825684130191803\n",
      "Epoch [320/600] and the accuracy is 0.761 and the loss is 0.48108482360839844\n",
      "Epoch [360/600] and the accuracy is 0.764 and the loss is 0.4795513451099396\n",
      "Epoch [400/600] and the accuracy is 0.765 and the loss is 0.477956622838974\n",
      "Epoch [440/600] and the accuracy is 0.765 and the loss is 0.47629404067993164\n",
      "Epoch [480/600] and the accuracy is 0.769 and the loss is 0.47455987334251404\n",
      "Epoch [520/600] and the accuracy is 0.767 and the loss is 0.4727548062801361\n",
      "Epoch [560/600] and the accuracy is 0.770 and the loss is 0.4708836078643799\n",
      "Epoch [600/600] and the accuracy is 0.770 and the loss is 0.46895501017570496\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    out = net(x_train)\n",
    "    loss = loss_fn(out,y_train.reshape(-1,1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    accuracy = (((out.reshape(-1) > .5)+0)==y_train).sum().numpy()/x_train.shape[0]\n",
    "    if (epoch+1) % 40 == 0:\n",
    "        print(\"Epoch [{}/{}] and the accuracy is {:.3f} and the loss is {}\".format(epoch+1, epochs, accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([154, 7])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([154])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8116883116883117"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((out > .5)+0).reshape(-1).float() == y_test).sum().numpy()/x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
